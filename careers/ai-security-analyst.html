<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Launch Your Future as an AI Security Analyst — SheTech Pathways</title>
<meta content="Secure AI systems and stop new kinds of digital threats!" name="description"/>
<link href="../styles.css" rel="stylesheet"/>
</head>
<body>
<header class="site-header">
<div class="container header-inner">
<a aria-label="Back to landing page" class="brand" href="../index.html">
<img alt="SheTech logo" class="brand-mark" src="../assets/shetech_logo_white.png"/>
<span class="brand-text">Pathways</span>
</a>
<nav aria-label="Primary" class="nav">
<a href="../index.html#careers">Careers</a>
<a href="../qr-sheet.html">QR sheet</a>
</nav>
</div>
</header>
<main class="page">
<div class="container">
<header class="page-header">
<p class="breadcrumbs">
<a href="../index.html">Home</a> <span aria-hidden="true">/</span>
<a href="../index.html#careers">Careers</a> <span aria-hidden="true">/</span>
            AI Security Analyst
          </p>
<h1 class="page-title">Launch Your Future as an AI Security Analyst</h1>
<p class="page-subtitle">Secure AI systems and stop new kinds of digital threats!</p>
</header>
<div class="content-grid">
<div>
<div class="career-hero" data-career-hero="" data-slug="ai-security-analyst" hidden="">
<img alt="AI Security Analyst hero image" class="career-hero-img" decoding="async" loading="lazy"/>
</div>
<!-- Google Doc-driven panels injected here -->
<div id="docSections"><section class="panel doc-panel" data-doc-section="pathway-snapshot"><h2>Pathway Snapshot</h2><div class="gdoc"><table class="sht-table sht-table-pathway"><tr><td><p><span>High School Courses</span></p></td><td><p><span>College Majors</span></p></td><td><p><span>Career Roles</span></p></td></tr><tr><td><p><span>Computer Science</span></p></td><td><p><span>Cybersecurity</span></p></td><td><p><span>AI Security Analyst</span></p></td></tr><tr><td><p><span>AP Computer Science</span></p></td><td><p><span>Computer Science</span></p></td><td><p><span>Machine Learning Security Engineer</span></p></td></tr><tr><td><p><span>Math (Algebra, Statistics)</span></p></td><td><p><span>Artificial Intelligence</span></p></td><td><p><span>AI Risk Analyst</span></p></td></tr><tr><td><p><span>Cybersecurity</span></p></td><td><p><span>Data Science</span></p></td><td><p><span>Trust &amp; Safety Engineer</span></p></td></tr><tr><td><p><span>Engineering</span></p></td><td><p><span>Information Systems</span></p></td><td><p><span>Cybersecurity Analyst (AI Focus)</span></p></td></tr></table></div></section>
<section class="panel doc-panel" data-doc-section="women-who-lead-the-way"><h2>Women Who Lead the Way</h2><div class="gdoc"><p><span>Elham Tabassi</span></p><p><span>Director, AI &amp; Emerging Technology Initiative, Brookings Institution</span></p><p><span><img alt="Image" decoding="async" loading="lazy" src="../assets/doc-images/ai-security-analyst-2.jpg"/></span></p><p><span>Photo Credit: NIST (National Institute of Standards and Technology)</span></p><p><span>"I love working in AI security because it lets me shape technology that people can trust—and ensure innovation benefits everyone."</span></p><p><span>Elham Tabassi is an American computer scientist and policy leader known for advancing trustworthy and responsible artificial intelligence (AI). A longtime senior researcher at the National Institute of Standards and Technology (NIST), she has been central to U.S. and international efforts to establish AI risk-management standards. In 2025 she became director of the Brookings Institution Artificial Intelligence and Emerging Technology Initiative.</span></p></div></section>
<section class="panel doc-panel" data-doc-section="day-in-the-life"><h2>Day in the Life</h2><div class="gdoc"><table class="sht-table sht-table-day"><tr><td><p><span>Daily Tasks</span></p></td><td><p><span>Tools &amp; Technologies Used</span></p></td></tr><tr><td><p><span>Test AI models for security risks and vulnerabilities</span></p></td><td><p><span>Python</span></p></td></tr><tr><td><p><span>Analyze how AI systems could be attacked or misused</span></p></td><td><p><span>Machine Learning Models</span></p></td></tr><tr><td><p><span>Monitor AI-powered systems for suspicious behavior</span></p></td><td><p><span>SIEM tools</span></p></td></tr><tr><td><p><span>Work with engineers to fix AI security gaps</span></p></td><td><p><span>Cloud platforms (AWS, Azure, GCP)</span></p></td></tr><tr><td><p><span>Review ethical, bias, and safety risks in AI</span></p></td><td><p><span>Threat modeling frameworks</span></p></td></tr></table><p><span></span></p></div></section>
<section class="panel doc-panel" data-doc-section="mini-activity:-try-this!"><h2>Mini-Activity: Try This!</h2><div class="gdoc"><p><span>AI Threat Detective <br/></span><span>Think of an AI system you use every day (voice assistants, facial recognition, recommendation apps).</span></p><ul><li><span>What data does it collect?</span></li><li><span>How could someone misuse or trick it?</span></li><li><span>What security rule would you add to protect it?</span></li></ul><p><span>You’re thinking like an</span><span> AI Security Analyst a</span><span>lready.</span></p></div></section>
<section class="panel doc-panel" data-doc-section="careers-&amp;-resources"><h2>Careers &amp; Resources</h2><div class="gdoc"><p><span>Explore Degrees</span></p><ul><li><span>College Board Major Search</span></li><li><span>Cybersecurity &amp; AI programs at universities and community colleges</span></li></ul><p><span>Scholarships</span></p><ul><li><span>Women in CyberSecurity (WiCyS) Scholarships</span></li><li><span>Girls Who Code Alumni Scholarships</span></li><li><span>College cybersecurity department awards</span></li></ul><p><span>Camps &amp; Bootcamps</span></p><ul><li><span>Girls Who Code Summer Immersion Program</span></li><li><span>CyberPatriot Camps</span></li><li><span>AI &amp; cybersecurity youth bootcamps</span></li></ul><p><span>Explore the Career</span></p><ul><li><span>O*NET Online – AI &amp; Cybersecurity roles</span></li><li><span>Roadtrip Nation – Tech &amp; cybersecurity stories</span></li><li><span>NIST AI Risk Management Framework (student-friendly resources)</span></li></ul></div></section>
<section class="panel doc-panel" data-doc-section="you-belong-here"><h2>You Belong Here</h2><div class="gdoc"><p><span>If you love problem-solving, puzzles, protecting people, technology, or thinking about how things could go wrong—and how to fix them—AI security could be your future.</span></p><p><span>You don’t have to choose between AI and cybersecurity.<br/>You don’t have to choose between ethics and technology.</span></p><p><span>As an AI Security Analyst, </span><span>you are the guardian of the future</span><span>.</span></p><p><span><img alt="Image" decoding="async" loading="lazy" src="../assets/doc-images/ai-security-analyst-3.jpg"/></span></p><p><span></span></p></div></section></div>
</div>
<aside class="side-stack">
<section class="panel">
<h2>Share this pathway</h2>
<div class="qr-box">
<img alt="QR code for AI Security Analyst pathway" data-path="./ai-security-analyst.html" data-qr="" height="200" width="200"/>
<p class="muted small">Set your public site URL on the landing page to generate scannable QR codes.</p>
</div>
<div class="side-actions">
<a class="btn btn-primary" href="../index.html#careers">All careers</a>
<button class="btn btn-ghost" data-copy-link="" data-path="./ai-security-analyst.html" type="button">Copy link</button>
</div>
</section>
</aside>
</div>
</div>
</main>
<footer class="site-footer">
<div class="container footer-inner">
<div class="footer-left">
<img alt="SheTech logo" class="footer-mark" loading="lazy" src="../assets/shetech_logo_teal.png"/>
<div>
<p class="footer-title">SheTech Pathways</p>
<p class="muted small">Explore more careers on the landing page.</p>
</div>
</div>
<div class="footer-right">
<a href="../index.html#careers">Careers</a>
</div>
</div>
</footer>
<script src="../careers-data.js"></script>
<script src="../doc-media.js"></script>
<script src="../script.js"></script>
</body>
</html>

